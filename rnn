import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# Model Architecture
classifier = Sequential()
DATASET_DIR = r'/content/drive/MyDrive/image/'
# Convolutional and Pooling layers
classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))
classifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))
classifier.add(Conv2D(32, (3, 3), activation='relu'))
classifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))

# Flattening
classifier.add(Flatten())

# Fully Connected Layers
classifier.add(Dense(units=128, activation='relu'))
classifier.add(Dense(units=1, activation='sigmoid'))

# Optimizer
from tensorflow.keras.optimizers import Adam

adam = Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False
)
classifier.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])

# Data Preprocessing
# ... (Your existing code for model architecture and optimizer) ...

# Data Preprocessing
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)
test_datagen = ImageDataGenerator(rescale=1.0 / 255)

# Load Training Data
training_set = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/image/',  # Path to your training data
    target_size=(64, 64),    # Resize images to match input_shape
    batch_size=32,
    class_mode='binary',      # Binary classification (cats vs. dogs)
    # Added validation_split for creating a validation set from training data
    validation_split=0.2
)

# Load Validation Data (from training set using validation_split)
validation_set = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/image/',
    target_size=(64, 64),
    batch_size=32,
    class_mode='binary',
    subset='validation'  # Use 'validation' subset
)

# Model Training
classifier.fit(
    training_set,
    steps_per_epoch=len(training_set),
    epochs=10,               # Adjust based on your needs
    validation_data=validation_set,  # Use validation_set instead of test_set
    validation_steps=len(validation_set)
)
